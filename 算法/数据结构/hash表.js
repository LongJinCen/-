// 一个桶，和我大一刷题的那个往后面插链表差不多，但是这个是经典哈希表。其他的不同的就是后面挂的不是链表，如树等
// 通过 hash 函数计算出一个code, 然后通过计算，得到一个索引，把这个值接到这个下边下
// 如果出现相同的，就把这个点挂在前一个点的后面

// 当链过长的时候，离线进行扩容，把数据都复制到新的哈希表里面，扩容好了再把用户流量切过来




// 例子1: 大数据，一个100T的文件，每个文件都是一行一行的，要求把重复的打印出来
// 基本上很多的大数据问题，都涉及到哈希函数。
// 可以一行一行的读取，然后通过哈希函数，计算出哈希值，例如有1000台机器，将计算出来的哈希值模1000，然后
// 转发到相同的机器上去。利用的就是哈希函数对于相同的输入必定有相同的输出这个特点

// 例子2: 定义一个函数，可以往哈希表里面添加字符串，也可以往里面删除字符串，并且需要定义一个函数getRadom。
// 可以使用match.random()获取索引，然后得到对应的值，这里的问题是哈希表没有索引，可以在这个函数内部维护一个index,当添加一个字符串的时候，index加一
// 以这个index为key,这个字符串为value,这样我们取的时候可以使用math.random()获取0~index之间的随机值，然后以这个值为key获取对应的字符串。
// 但是当我们删除一个字符串的时候，需要以字符串为key,所以我们需要维护两个哈希表，一个的键为index，值为字符串的值，另一个则相反，在获取和设置的时候，
// 都需要去更新两张表
// 删除的时候麻烦一点，为了防止删除后，中间的index不连续，先在一张表中获取这个字符串对应的index, 然后删除以改字符串为key的记录，然后拿到index后，再去另一张表
// 将这张表中index最大的那条记录对应的值设置到前面我们要删除的那条记录对应的index为key的值，最后将这张表
// 最后的这条记录所对应的string拿到第一张表中去，去将以它为key的值设置为我们要删除的index，并将总的index减一